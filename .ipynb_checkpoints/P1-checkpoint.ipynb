{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook is also available on my GitHub (https://github.com/amr-ayoub/CarND-LaneLines-P1.git)\n",
    "\n",
    "\n",
    "*The following libraries are used:\n",
    "\n",
    "    OpenCV\n",
    "    Numpy \n",
    "    MoviePy\n",
    "    sklearn (LinearRegression)\n",
    "\n",
    "\n",
    "Implementation:\n",
    "\n",
    "1- Reads image.\n",
    "2- Convert image to gray.\n",
    "3- Apply gaussian blur\n",
    "4- Canny edge detection\n",
    "5- Apply region of interest mask\n",
    "6- Run Hough transform\n",
    "7- Determine the lines with the accepted slope and draw them in RED color\n",
    "8- Draw the longest right and left lines in BLUE after doing extrapolation on them\n",
    "9- Feed accepted lines plus the extrapolated dominant longest lines to a linear regression to get the main left and right\n",
    "   lane lines and draw them in WHITE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    #importing some useful packages\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "    \n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=4):\n",
    "    \"\"\"\n",
    "    Draw lines on image:\n",
    "    \n",
    "    - Determine the lines with the accepted slope\n",
    "      and draw them in red color\n",
    "      \n",
    "    - Draw the longest right and left lines in blue\n",
    "      after Extrapolation\n",
    "      \n",
    "    - collect the accepted lines plus extrapolated longest lines\n",
    "      and use them to do\n",
    "      a linear regression to get the main left and right\n",
    "      lane lines and draw them in white \n",
    "    \"\"\"\n",
    "    \n",
    "    height = img.shape[0]  #height of the image\n",
    "    width = img.shape[1]   #width\n",
    "    \n",
    "    # min and max allowed slopes\n",
    "    min_slope = (height/3.0)/(width/2.0)\n",
    "    max_slope = 0.9\n",
    "    \n",
    "    # longest_left and right used to store longest left \n",
    "    # and right lines to draw them in Green color\n",
    "    longest_left = [0,0,0,0]\n",
    "    longest_right = [0,0,0,0]\n",
    "    \n",
    "    # X_right and Y_right will be used to collect accepted \n",
    "    # lines end points to be used in linear regression\n",
    "    # to get main lane lines wich is drawn in white color\n",
    "    X_right = []\n",
    "    Y_right = []\n",
    "    \n",
    "    # X_left and Y_left will be used to collect accepted \n",
    "    # lines end points to be used in linear regression\n",
    "    # to get main lane lines wich is drawn in White color\n",
    "    X_left = []\n",
    "    Y_left = []\n",
    "    \n",
    "    \n",
    "    # Draw only lines in the acceptable slopes in red color\n",
    "    # Collect the end points for the accepted lines to \n",
    "    # do linear regression to get the main left and \n",
    "    # right lane lines\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            # calculate slope\n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "                       \n",
    "            # Checking if the line in the accepted range to be drawn\n",
    "            if ((abs(slope) > min_slope) and ((abs(slope) < max_slope))):\n",
    "                #Draw lines with accepted slopes in red\n",
    "                cv2.line(img, (x1, y1), (x2, y2), [255,0,0], 4)\n",
    "                \n",
    "                #find the longest line on the right\n",
    "                if (slope > 0):\n",
    "                    line_length = math.sqrt((y2-y1)**2 + (x2-x1)**2)\n",
    "                \n",
    "                    xx1,yy1,xx2,yy2 = longest_right\n",
    "                    longest_length = math.sqrt((yy2-yy1)**2 + (xx2-xx1)**2)\n",
    "                \n",
    "                    if (line_length > longest_length):\n",
    "                        longest_right = line[0]\n",
    "            \n",
    "                #find the longest line on the left\n",
    "                if (slope < 0):\n",
    "                    line_length = math.sqrt((y2-y1)**2 + (x2-x1)**2)\n",
    "                \n",
    "                    xx1,yy1,xx2,yy2 = longest_left\n",
    "                    longest_length = math.sqrt((yy2-yy1)**2 + (xx2-xx1)**2)\n",
    "                \n",
    "                    if (line_length > longest_length):\n",
    "                        longest_left = line[0]\n",
    "            \n",
    "                #collecting points from the right lines for linear regression\n",
    "                if (slope > 0):\n",
    "                    X_right.append(x1)\n",
    "                    Y_right.append(y1)\n",
    "                    X_right.append(x2)\n",
    "                    Y_right.append(y2)\n",
    "            \n",
    "                #collecting points from the left lines for linear regression\n",
    "                if (slope < 0):\n",
    "                    X_left.append(x1)\n",
    "                    Y_left.append(y1)\n",
    "                    X_left.append(x2)\n",
    "                    Y_left.append(y2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #draw extrapolated longest right lines in Blue\n",
    "    x1,y1,x2,y2 = longest_right\n",
    "    extra_right = LinearRegression().fit([[x1],[x2]],[[y1],[y2]])\n",
    "    m_extta_right = extra_right.coef_[0]\n",
    "    b_extta_right_ = extra_right.intercept_\n",
    "    \n",
    "    extra_right_x1 = (width*6) //10\n",
    "    extra_right_x2 = width\n",
    "    \n",
    "    extra_right_y1 = int (m_extta_right*extra_right_x1 + b_extta_right_)\n",
    "    extra_right_y2 = int (m_extta_right*extra_right_x2 + b_extta_right_)\n",
    "    \n",
    "    cv2.line(img, (extra_right_x1, extra_right_y1), (extra_right_x2, extra_right_y2), [0,0,255], 10)\n",
    " \n",
    "    \n",
    "    # Add extrapolated right to the linear regression\n",
    "    X_right.append(extra_right_x1)\n",
    "    Y_right.append(extra_right_y1)\n",
    "    X_right.append(extra_right_x2)\n",
    "    Y_right.append(extra_right_y2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #draw extrapolated longest left lines in Blue\n",
    "    x1,y1,x2,y2 = longest_left\n",
    "    extra_left = LinearRegression().fit([[x1],[x2]],[[y1],[y2]])\n",
    "    m_extta_left = extra_left.coef_[0]\n",
    "    b_extta_left_ = extra_left.intercept_\n",
    "    \n",
    "    extra_left_x1 = (width *2) //5\n",
    "    extra_left_x2 = 0\n",
    "    \n",
    "    extra_left_y1 = int (m_extta_left*extra_left_x1 + b_extta_left_)\n",
    "    extra_left_y2 = int (m_extta_left*extra_left_x2 + b_extta_left_)\n",
    "    \n",
    "    cv2.line(img, (extra_left_x1, extra_left_y1), (extra_left_x2, extra_left_y2), [0,0,255], 10)\n",
    " \n",
    "    \n",
    "    # Add extrapolated left to the linear regression\n",
    "    X_left.append(extra_left_x1)\n",
    "    Y_left.append(extra_left_y1)\n",
    "    X_left.append(extra_left_x2)\n",
    "    Y_left.append(extra_left_y2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #do a linear regression to get main right line\n",
    "    X_right = np.reshape(X_right, (len(X_right),1))\n",
    "    Y_right = np.reshape(Y_right, (len(Y_right),1))\n",
    "    mdl = LinearRegression().fit(X_right,Y_right)\n",
    "    m = mdl.coef_[0]\n",
    "    b = mdl.intercept_\n",
    "    \n",
    "    \n",
    "    #determine end points for the main right lane line\n",
    "    # y = mx + b\n",
    "    right_x1 = (width *3) //5\n",
    "    right_x2 = width\n",
    "    \n",
    "    right_y1 = int (m*right_x1 + b)\n",
    "    right_y2 = int (m*right_x2 + b) \n",
    "    \n",
    "    #draw the main right lane line in White\n",
    "    cv2.line(img, (right_x1, right_y1), (right_x2, right_y2), [255,255,255], 10)\n",
    "    \n",
    "          \n",
    "    #do a linear regression to get main left line\n",
    "    X_left = np.reshape(X_left, (len(X_left),1))\n",
    "    Y_left = np.reshape(Y_left, (len(Y_left),1))\n",
    "    mdl = LinearRegression().fit(X_left,Y_left)\n",
    "    m = mdl.coef_[0]\n",
    "    b = mdl.intercept_\n",
    "    \n",
    "    \n",
    "    #determine end points for the main left lane line\n",
    "    # y = mx + b\n",
    "    left_x1 = (width *2) //5\n",
    "    left_x2 = 0\n",
    "    \n",
    "    left_y1 = int (m*left_x1 + b)\n",
    "    left_y2 = int (m*left_x2 + b) \n",
    "    \n",
    "    #draw the main left lane line in White\n",
    "    cv2.line(img, (left_x1, left_y1), (left_x2, left_y2), [255,255,255], 10)\n",
    "\n",
    "    \n",
    "    return img\n",
    "            \n",
    "    \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    filtered_line_img = draw_lines(line_img, lines)\n",
    "    return filtered_line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images\n",
    "\n",
    "Now you should build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Build your pipeline that will draw lane lines on the test_images\n",
    "# then save them to the test_images directory.\n",
    "\n",
    "images = os.listdir(\"test_images/\")\n",
    "\n",
    "for img in images:\n",
    "    #starting with reading image\n",
    "    image = mpimg.imread(\"test_images/\" + img)\n",
    "\n",
    "    #Convert image to grayscale\n",
    "    gray = grayscale(image)\n",
    "\n",
    " \n",
    "    #Apply Guassian blur\n",
    "    kernel_size = 5\n",
    "    gray_blur = gaussian_blur(gray, kernel_size)\n",
    "\n",
    "\n",
    "\n",
    "    #Canny edge detection\n",
    "    low_threshold = 80\n",
    "    high_threshold = 200\n",
    "    edges = canny(gray_blur, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "    #Apply region of interest mask\n",
    "    hight = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    width_segment = int(width/2.5)  #width segment used in ROI vertics\n",
    "\n",
    "    vertices = np.array([[(0,hight),(width_segment,320), ((width-width_segment),320), (width,hight)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges,vertices)\n",
    "\n",
    " \n",
    "    #Run Hough transform\n",
    "    rho = 2\n",
    "    theta = np.pi / 180 \n",
    "    threshold = 20\n",
    "    min_line_len = 20 \n",
    "    max_line_gap = 10\n",
    "\n",
    "\n",
    "    lines_image = hough_lines(masked_edges, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "\n",
    "\n",
    "    # Draw the lines on the initial image using weighted_img\n",
    "    result_image = weighted_img(lines_image,image)\n",
    "    plt.imshow(result_image)\n",
    "    plt.figure()\n",
    "      \n",
    "    # write images with lines to test_images directory\n",
    "    plt.savefig(\"test_images/\" + \"edited_\" + img)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    \n",
    "    #Convert image to grayscale\n",
    "    gray = grayscale(image)\n",
    "\n",
    "    #Apply Guassian blur\n",
    "    kernel_size = 5\n",
    "    gray_blur = gaussian_blur(gray, kernel_size)\n",
    "\n",
    "    #Canny edge detection\n",
    "    low_threshold = 80\n",
    "    high_threshold = 200\n",
    "    edges = canny(gray_blur, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "    #Apply region of interest mask\n",
    "    hight = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    width_segment = int(width/2.5)  #width segment used in ROI vertics\n",
    "\n",
    "    vertices = np.array([[(0,hight),(width_segment,320), ((width-width_segment),320), (width,hight)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges,vertices)\n",
    "\n",
    "\n",
    "    #Run Hough transform\n",
    "    rho = 2\n",
    "    theta = np.pi / 180 \n",
    "    threshold = 20\n",
    "    min_line_len = 20 \n",
    "    max_line_gap = 10\n",
    "\n",
    "\n",
    "    lines_image = hough_lines(masked_edges, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "\n",
    "    #Draw the lines on the initial image using weighted_img\n",
    "    result = weighted_img(lines_image,image)\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:04<00:00, 48.16it/s]     | 7/222 [00:00<00:03, 63.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 2.76 s, sys: 188 ms, total: 2.95 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a4e239a08e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m HTML(\"\"\"\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"960\"\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"540\"\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;34m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{0}\"\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\".format(white_output))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HTML' is not defined"
     ]
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:15<00:00, 44.08it/s]     | 6/682 [00:00<00:11, 58.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 8.98 s, sys: 504 ms, total: 9.49 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "- Finding lane assumes that there is at least one solid lane line for the left and the right.\n",
    "- Works only on lines not curves.\n",
    "- Assumes images are in clear weather\n",
    "- Assumes the camera is stationary and at the same position.\n",
    "\n",
    "\n",
    "The drawn lane lines not very stable, they jitters between frames, so we need an averaging\n",
    "way among lane lines of the successive frames.\n",
    "\n",
    "The idea of building the algorithm based on dominant lines on the left and write will not\n",
    "work for curved roads.\n",
    "\n",
    "Also the algorithm assumes at least there is one solid line one left and write will not make \n",
    "it valid for roads with dots marks instead of lines or roads with faded lines.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "If you're satisfied with your video outputs it's time to submit!  Submit this ipython notebook for review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
